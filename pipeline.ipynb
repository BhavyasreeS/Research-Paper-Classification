{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oHaMRRPncink",
    "outputId": "871e0a20-c611-4984-cfbd-c2f0b2d16b37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: luigi in /usr/local/lib/python3.7/dist-packages (3.0.3)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.1)\n",
      "Requirement already satisfied: python-daemon in /usr/local/lib/python3.7/dist-packages (from luigi) (2.3.0)\n",
      "Requirement already satisfied: tenacity<7,>=6.3.0 in /usr/local/lib/python3.7/dist-packages (from luigi) (6.3.1)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.5 in /usr/local/lib/python3.7/dist-packages (from luigi) (2.8.1)\n",
      "Requirement already satisfied: tornado<7,>=5.0 in /usr/local/lib/python3.7/dist-packages (from luigi) (5.1.1)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
      "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: lockfile>=0.10 in /usr/local/lib/python3.7/dist-packages (from python-daemon->luigi) (0.12.2)\n",
      "Requirement already satisfied: docutils in /usr/local/lib/python3.7/dist-packages (from python-daemon->luigi) (0.17.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-daemon->luigi) (56.1.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from tenacity<7,>=6.3.0->luigi) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install luigi transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "DxCG68BEapNv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import luigi\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "import bert\n",
    "import trainer\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "hPl8Z_Bua5pf"
   },
   "outputs": [],
   "source": [
    "artifact_directory = \"artifacts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "6EQSvKqUa-Xr"
   },
   "outputs": [],
   "source": [
    "class LoadData(luigi.Task):\n",
    "\n",
    "    def output(self):\n",
    "        return luigi.LocalTarget(os.path.join(artifact_directory, \"data.pkl\"))\n",
    "\n",
    "    def run(self):\n",
    "        data = pd.read_csv(\"train.csv\")\n",
    "        with open(self.output().path, \"wb\") as outfile:\n",
    "            pickle.dump(data, outfile)\n",
    "        print(\"Data loading done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "GQmXG3mpbDCE"
   },
   "outputs": [],
   "source": [
    "class TrainModel(luigi.Task):\n",
    "\n",
    "    def requires(self):\n",
    "        return LoadData()\n",
    "\n",
    "    def run(self):\n",
    "        classes = [\"Computer Science\", \"Physics\", \"Mathematics\", \"Statistics\", \"Quantitative Biology\",\n",
    "                   \"Quantitative Finance\"]\n",
    "        with open(self.input().path, \"rb\") as in_file:\n",
    "            data = pd.read_pickle(in_file)\n",
    "        data[\"text\"] = data[\"TITLE\"] + \" .\" + data[\"ABSTRACT\"]\n",
    "        Y = data[classes].values\n",
    "        version = \"final_1\"\n",
    "        processors = [utils.replace_latex_math_with, utils.to_corpus, utils.lemmatize_sentence]\n",
    "        model = bert.BertToSingleLayerNeuralNetwork(config=bert.ModelConfig)\n",
    "        model.version = version\n",
    "        model.build(processors=processors)\n",
    "        trainer_methodology = trainer.KFoldTrainer(config=trainer.TrainerConfig, model=model)\n",
    "        trainer_methodology.initialize(x=data[\"text\"], y=Y)\n",
    "        model.save(\"artifacts\")\n",
    "        with self.output().open(\"w\") as file:\n",
    "            file.write(\"artifacts\")\n",
    "\n",
    "    def output(self):\n",
    "        return luigi.LocalTarget('model_path.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "4s5_FPLGbJds"
   },
   "outputs": [],
   "source": [
    "class EvaluateModel(luigi.Task):\n",
    "\n",
    "    def requires(self):\n",
    "        return TrainModel()\n",
    "\n",
    "    def run(self):\n",
    "        version = \"final_1\"\n",
    "        processors = [utils.replace_latex_math_with, utils.to_corpus, utils.lemmatize_sentence]\n",
    "        model = bert.BertToSingleLayerNeuralNetwork(config=bert.ModelConfig)\n",
    "        model.version = version\n",
    "        model.build(processors=processors)\n",
    "        with open(self.input().path, \"r\") as input_file:\n",
    "            directory = input_file.read()\n",
    "        print(\"loading model from \", directory)\n",
    "        model.load(directory=directory)\n",
    "\n",
    "        validation_dataset = pd.read_csv(\"train.csv\")\n",
    "        validation_dataset[\"text\"] = validation_dataset[\"TITLE\"] + \" .\" + validation_dataset[\"ABSTRACT\"]\n",
    "        y_pred = model.predict(validation_dataset[\"text\"])\n",
    "\n",
    "        classes = [\"Computer Science\", \"Physics\", \"Mathematics\", \"Statistics\", \"Quantitative Biology\",\n",
    "                   \"Quantitative Finance\"]\n",
    "        Y_val = validation_dataset[classes].values\n",
    "        y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "        f1Score = f1_score(Y_val, y_pred_binary, average='macro')\n",
    "        print(f1Score)\n",
    "        with self.output().open(\"w\") as file:\n",
    "            file.write(\"artifacts\")        \n",
    "\n",
    "    def output(self):\n",
    "        return luigi.LocalTarget('eval.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "rsbGSHYp2jU2"
   },
   "outputs": [],
   "source": [
    "class DeployModel(luigi.Task):\n",
    "\n",
    "  def requires(self):\n",
    "        return EvaluateModel()\n",
    "  def run(self):\n",
    "        version = \"final_1\"\n",
    "        processors = [utils.replace_latex_math_with, utils.to_corpus, utils.lemmatize_sentence]\n",
    "        model = bert.BertToSingleLayerNeuralNetwork(config=bert.ModelConfig)\n",
    "        model.version = version\n",
    "        model.build(processors=processors)\n",
    "        with open(self.input().path, \"r\") as input_file:\n",
    "            directory = input_file.read()\n",
    "        print(\"loading model from \", directory)\n",
    "        model.load(directory=directory)\n",
    "        model.save(\"model\")\n",
    "        with self.output().open(\"w\") as file:\n",
    "            file.write(\"artifacts\")        \n",
    "\n",
    "  def output(self):\n",
    "      return luigi.LocalTarget('deploy.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2G6FFfusdZuO",
    "outputId": "990096b4-cf22-46f4-e90e-cc7d075a0b19"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: Checking if DeployModel() is complete\n",
      "DEBUG: Checking if EvaluateModel() is complete\n",
      "INFO: Informed scheduler that task   DeployModel__99914b932b   has status   PENDING\n",
      "DEBUG: Checking if TrainModel() is complete\n",
      "INFO: Informed scheduler that task   EvaluateModel__99914b932b   has status   PENDING\n",
      "INFO: Informed scheduler that task   TrainModel__99914b932b   has status   DONE\n",
      "INFO: Done scheduling tasks\n",
      "INFO: Running Worker with 1 processes\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Pending tasks: 2\n",
      "INFO: [pid 59] Worker Worker(salt=033068874, workers=1, host=05ee1e0ab1b7, username=root, pid=59) running   EvaluateModel()\n",
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "loading model from  artifacts\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [pid 59] Worker Worker(salt=033068874, workers=1, host=05ee1e0ab1b7, username=root, pid=59) done      EvaluateModel()\n",
      "DEBUG: 1 running tasks, waiting for next task to finish\n",
      "INFO: Informed scheduler that task   EvaluateModel__99914b932b   has status   DONE\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Pending tasks: 1\n",
      "INFO: [pid 59] Worker Worker(salt=033068874, workers=1, host=05ee1e0ab1b7, username=root, pid=59) running   DeployModel()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1745849829935736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "loading model from  artifacts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: [pid 59] Worker Worker(salt=033068874, workers=1, host=05ee1e0ab1b7, username=root, pid=59) done      DeployModel()\n",
      "DEBUG: 1 running tasks, waiting for next task to finish\n",
      "INFO: Informed scheduler that task   DeployModel__99914b932b   has status   DONE\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Done\n",
      "DEBUG: There are no more tasks to run at this time\n",
      "INFO: Worker Worker(salt=033068874, workers=1, host=05ee1e0ab1b7, username=root, pid=59) was stopped. Shutting down Keep-Alive thread\n",
      "INFO: \n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 3 tasks of which:\n",
      "* 1 complete ones were encountered:\n",
      "    - 1 TrainModel()\n",
      "* 2 ran successfully:\n",
      "    - 1 DeployModel()\n",
      "    - 1 EvaluateModel()\n",
      "\n",
      "This progress looks :) because there were no failed tasks or missing dependencies\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luigi.build([DeployModel()], local_scheduler=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python index.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "pipeline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
